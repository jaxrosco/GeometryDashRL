{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import time\n",
    "import win32gui\n",
    "import win32con\n",
    "import cv2\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "\n",
    "class GeometryDashEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(GeometryDashEnv, self).__init__()\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(360, 640, 1), dtype=np.uint8)\n",
    "        self.sct = mss()\n",
    "        self.window_name = \"Geometry Dash\"\n",
    "        self.window_rect = self._get_window_rect()\n",
    "        self.seen_columns = set()\n",
    "        self.menu_template = self._load_template('templates/menu_template.png')\n",
    "        pyautogui.press('space')\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        time.sleep(0.2)\n",
    "        self.seen_columns.clear()\n",
    "        pyautogui.press('space')\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        self._execute_action(action)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        obs = self._get_observation()\n",
    "    \n",
    "        if self._is_game_over(obs):\n",
    "            reward = -15\n",
    "            obs, _ = self.reset()\n",
    "            terminated = True\n",
    "            truncated = False\n",
    "        else:\n",
    "            reward = self._calculate_reward(obs, action)\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            \n",
    "        return obs, reward, terminated, truncated, {}\n",
    "\n",
    "    def _get_window_rect(self):\n",
    "        hwnd = win32gui.FindWindow(None, self.window_name)\n",
    "        if hwnd == 0:\n",
    "            raise RuntimeError(\"Window not found. Ensure the game is running and titled 'Geometry Dash'.\")\n",
    "        \n",
    "        win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        try:\n",
    "            win32gui.SetForegroundWindow(hwnd) # If SetForegroundWindow() is not working, try using SetActiveWindow().\n",
    "        except Exception as e:\n",
    "            print(f\"Error bringing window to the foreground: {e}\")\n",
    "            raise\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        rect = win32gui.GetWindowRect(hwnd)\n",
    "        return {\"top\": rect[1], \"left\": rect[0], \"width\": rect[2] - rect[0], \"height\": rect[3] - rect[1]}\n",
    "\n",
    "    def _load_template(self, path):\n",
    "        template = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if template is None:\n",
    "            raise FileNotFoundError(f\"Template image not found at {path}.\")\n",
    "        return cv2.resize(template, (640, 360))\n",
    "\n",
    "    def _is_game_over(self, obs):\n",
    "        obs = obs.squeeze().astype(np.uint8)\n",
    "        result = cv2.matchTemplate(obs, self.menu_template, cv2.TM_CCOEFF_NORMED)\n",
    "        _, max_val, _, _ = cv2.minMaxLoc(result)\n",
    "        return max_val >= 0.7 # Game is over if match is >= to 70%\n",
    "\n",
    "    def _calculate_reward(self, obs, action):\n",
    "        reward = 0\n",
    "        right_columns = obs[:, -5:]\n",
    "        column_hash = self._hash_observation(right_columns)\n",
    "        \n",
    "        if column_hash not in self.seen_columns:\n",
    "            self.seen_columns.add(column_hash)\n",
    "            reward += 1\n",
    "\n",
    "        if action == 1:\n",
    "            reward -= 0.05\n",
    "        elif action == 2:\n",
    "            reward -= 0.5\n",
    "        \n",
    "        return reward\n",
    " \n",
    "    def _get_observation(self):\n",
    "        screenshot = self.sct.grab(self.window_rect)\n",
    "        img = Image.frombytes(\"RGB\", (screenshot.width, screenshot.height), screenshot.rgb)\n",
    "        img = img.convert(\"L\").resize((640, 360))\n",
    "        img = np.array(img)[..., np.newaxis]\n",
    "        return img\n",
    "\n",
    "    def _hash_observation(self, observation):\n",
    "        return hashlib.sha256(observation.tobytes()).hexdigest()\n",
    "\n",
    "    def _execute_action(self, action):\n",
    "        if action == 1:\n",
    "            pyautogui.press('w')\n",
    "        elif action == 2:\n",
    "            pyautogui.keyDown('w')\n",
    "        else:\n",
    "            pyautogui.keyUp('w')\n",
    "\n",
    "    # Here to avoid errors, not necessary\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        self.sct.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Environment Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test environment with random actions\n",
    "# Using matplotlib to visualize steps\n",
    "\n",
    "env = GeometryDashEnv()\n",
    "plt.ion()\n",
    "\n",
    "num_episodes = 3\n",
    "max_steps = 100\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(f\"\\n--- Episode {episode + 1} ---\")\n",
    "    obs, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        \n",
    "        plt.imshow(obs.squeeze(), cmap='gray')\n",
    "        plt.title(f'Episode {episode + 1}, Step {step + 1}\\nAction: {action}, Reward: {reward}')\n",
    "        plt.axis('off')\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)\n",
    "        \n",
    "        print(f\"Step {step + 1}: Action={action}, Reward={reward}, Terminated={terminated}\")\n",
    "        \n",
    "        total_reward += reward\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            print(\"Episode ended due to termination.\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Total Reward for Episode {episode + 1}: {total_reward}\")\n",
    "\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n",
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 3      |\n",
      "|    iterations      | 1      |\n",
      "|    time_elapsed    | 2507   |\n",
      "|    total_timesteps | 253952 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 5126       |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23624259 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.375     |\n",
      "|    explained_variance   | 0.60734665 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.385      |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7757       |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21615687 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.367     |\n",
      "|    explained_variance   | 0.7566829  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.247      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 7.07       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 10416      |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17414606 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.382     |\n",
      "|    explained_variance   | 0.7961393  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.344      |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    value_loss           | 6.4        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 13071      |\n",
      "|    total_timesteps      | 286720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15591687 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.355     |\n",
      "|    explained_variance   | 0.7856302  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.398      |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    value_loss           | 7.49       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 15720      |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17148355 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.364     |\n",
      "|    explained_variance   | 0.744069   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.308      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 8.44       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 18361      |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19643004 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.36      |\n",
      "|    explained_variance   | 0.74516857 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.543      |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    value_loss           | 8.2        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 20970      |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18558314 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.7383325  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.67       |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    value_loss           | 6.91       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 23607      |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16691016 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.352     |\n",
      "|    explained_variance   | 0.7753848  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.879      |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.026     |\n",
      "|    value_loss           | 5.98       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3          |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 26233      |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16985917 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.75976217 |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.537      |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 6.45       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = GeometryDashEnv()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Load existing model\n",
    "model = PPO.load(\"models/nopurrius3\", env=env, device='cuda')\n",
    "\n",
    "# Save temp model\n",
    "model.save(\"models/temp_nopurrius\")\n",
    "\n",
    "# Create new model\n",
    "model = PPO(\"CnnPolicy\", env, n_steps=4096, batch_size=64, learning_rate=0.0003, device='cuda', verbose=1)\n",
    "\n",
    "model = model.load(\"models/temp_nopurrius\", env=env, device='cuda')\n",
    "\n",
    "model.learn(total_timesteps=81920, reset_num_timesteps=False)\n",
    "model.save(\"models/nopurrius3\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an existing model\n",
    "\n",
    "model = PPO.load(\"models/nopurrius3\")\n",
    "env = GeometryDashEnv()\n",
    "\n",
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, terminated, _, _ = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        obs, _ = env.reset()\n",
    "        # To test one attempt\n",
    "        # break\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
